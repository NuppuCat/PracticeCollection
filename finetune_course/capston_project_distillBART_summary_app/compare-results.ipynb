{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install  evaluate rouge_score\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:38:52.388515Z","iopub.execute_input":"2025-03-14T13:38:52.388825Z","iopub.status.idle":"2025-03-14T13:38:59.204365Z","shell.execute_reply.started":"2025-03-14T13:38:52.388792Z","shell.execute_reply":"2025-03-14T13:38:59.203213Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.3.1)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.29.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=ef12adf0f6f6331ac458ed20d7c0191c3b9e7c6498b175eb9ffa0f420c055cac\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score, evaluate\nSuccessfully installed evaluate-0.4.3 rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#load the distilled model\ntokenizer = AutoTokenizer.from_pretrained(\"NuppuCat/distillBart-6-6-1000xsum-8epoche\")\nstudent = AutoModelForSeq2SeqLM.from_pretrained(\"NuppuCat/distillBart-6-6-1000xsum-8epoche\").to(device)\n\n\n# 1. 加载教师模型和学生模型\n#load the teacher model\nteacher_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/bart-large-cnn\").to(device)\n# 教师模型只用于生成软标签，因此设为eval模式，不进行反向传播\nteacher_model.eval()\nstudent.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:38:59.205581Z","iopub.execute_input":"2025-03-14T13:38:59.205970Z","iopub.status.idle":"2025-03-14T13:39:36.981355Z","shell.execute_reply.started":"2025-03-14T13:38:59.205938Z","shell.execute_reply":"2025-03-14T13:39:36.980544Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"810c03bc4890446fa8ca046de89b5983"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d8664b140bb4ce4af75442f1ff7128a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14bf65269b7a4f3fa9b0583f8fe94531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/3.56M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e33be1062524f65a3ab6e2c040e1ef1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c022506678cb4f28b552bb99df5a6c25"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f06c95cdbbc4b0aba11a48b4c5fed83"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/models/bart/configuration_bart.py:176: UserWarning: Please make sure the config includes `forced_bos_token_id=0` in future versions. The config can simply be saved and uploaded again to be fixed.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/920M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6bf53ac01674dd4b1c42f764288424f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/358 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d2123a69af746a0a1f4e5b967b0f26d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.58k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75d59a9047b941e89cd2fe4466bea1d5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d48fcb55cfa247388567126cc0952b5e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a74ac49c4144e03878bd5b5793b25cf"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"BartForConditionalGeneration(\n  (model): BartModel(\n    (shared): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n    (encoder): BartEncoder(\n      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-5): 6 x BartEncoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (activation_fn): GELUActivation()\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n    (decoder): BartDecoder(\n      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n      (layers): ModuleList(\n        (0-5): 6 x BartDecoderLayer(\n          (self_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (activation_fn): GELUActivation()\n          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (encoder_attn): BartSdpaAttention(\n            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n          )\n          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        )\n      )\n      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"# function to calculate the model size\ndef get_model_size(model):\n    param_size = sum(p.numel() * p.element_size() for p in model.parameters())  # 计算参数占用\n    buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())  # 计算缓冲区占用\n    total_size = param_size + buffer_size  # 总大小（字节）\n    return total_size / (1024 ** 2)  # 转换为 MB\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:39:36.982267Z","iopub.execute_input":"2025-03-14T13:39:36.982992Z","iopub.status.idle":"2025-03-14T13:39:36.987699Z","shell.execute_reply.started":"2025-03-14T13:39:36.982948Z","shell.execute_reply":"2025-03-14T13:39:36.986719Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import evaluate\nfrom datasets import load_dataset\nfrom tqdm import tqdm\n# 加载 XSum 测试集前 20 个样本\n#This time test 200 samples\n#First test the performance of the distilled model\ntest_dataset = load_dataset(\"EdinburghNLP/xsum\", split=\"test[:200]\")\n\n# ROUGE 计算器\nrouge = evaluate.load(\"rouge\")\n\n# 生成摘要并收集结果\ngenerated_summaries = []\nreference_summaries = []\n\nfor sample in tqdm(test_dataset):\n    article = sample[\"document\"]\n    reference_summary = sample[\"summary\"]\n\n    # 编码输入\n    inputs = tokenizer(\n        article,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=1024,\n        padding=\"max_length\"\n    ).to(device)\n\n    # 生成摘要\n    summary_ids = student.generate(\n        **inputs,\n        max_length=400,\n        num_beams=4,\n        length_penalty=2.0,\n        no_repeat_ngram_size=3,\n        early_stopping=True\n    )\n\n    # 解码生成的摘要\n    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n    generated_summaries.append(generated_summary)\n    reference_summaries.append(reference_summary)\n\n# 计算 ROUGE 分数\nresults = rouge.compute(\n    predictions=generated_summaries,\n    references=reference_summaries,\n    use_stemmer=True\n)\n\n# 打印结果\nprint('Student model')\nprint(f\"Model size: {get_model_size(student):.2f} MB\")\nfor key in results:\n    print(f\"{key}: {results[key]*100:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:39:36.989502Z","iopub.execute_input":"2025-03-14T13:39:36.989764Z","iopub.status.idle":"2025-03-14T13:40:50.113494Z","shell.execute_reply.started":"2025-03-14T13:39:36.989742Z","shell.execute_reply":"2025-03-14T13:40:50.112827Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/6.24k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4da665dba444b23bc6b38f486e0909e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"xsum.py:   0%|          | 0.00/5.76k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a972a0ed706b4c348e20eaef546c7a06"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/304M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51171cd5057c4e478449bfcd16b267f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/16.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f9fff7db50f483e9a89d3ce5bf4ac2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0000.parquet:   0%|          | 0.00/17.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4357088d77a341179f92cbc8169295e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/204045 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1a7d4b27e4a4562ad89b93ae6a6bfdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/11332 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84819ecd8fc24188b85cacce046d59ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/11334 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe030680c4f0457ca8d88e44cddb27f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcc564a2b4d54b68bc2129b5d83efebd"}},"metadata":{}},{"name":"stderr","text":"  0%|          | 0/200 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1527: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed in v5. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n  warnings.warn(\n100%|██████████| 200/200 [01:01<00:00,  3.26it/s]\n","output_type":"stream"},{"name":"stdout","text":"Student model\nModel size: 877.32 MB\nrouge1: 30.72\nrouge2: 9.68\nrougeL: 23.79\nrougeLsum: 23.77\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import evaluate\nfrom datasets import load_dataset\nfrom tqdm import tqdm\n# 加载 XSum 测试集前 20 个样本\ntest_dataset = load_dataset(\"EdinburghNLP/xsum\", split=\"test[:200]\")\n#Use same test model to test the teacher model\n# ROUGE 计算器\nrouge = evaluate.load(\"rouge\")\n\n# 生成摘要并收集结果\ngenerated_summaries = []\nreference_summaries = []\n\nfor sample in tqdm(test_dataset):\n    article = sample[\"document\"]\n    reference_summary = sample[\"summary\"]\n\n    # 编码输入\n    inputs = tokenizer(\n        article,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=1024,\n        padding=\"max_length\"\n    ).to(device)\n\n    # 生成摘要\n    summary_ids = teacher_model.generate(\n        **inputs,\n        max_length=400,\n        num_beams=4,\n        length_penalty=2.0,\n        no_repeat_ngram_size=3,\n        early_stopping=True\n    )\n\n    # 解码生成的摘要\n    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n    generated_summaries.append(generated_summary)\n    reference_summaries.append(reference_summary)\n\n# 计算 ROUGE 分数\nresults = rouge.compute(\n    predictions=generated_summaries,\n    references=reference_summaries,\n    use_stemmer=True\n)\n\n# 打印结果\nprint('teacher_model')\nprint(f\"Model size: {get_model_size(teacher_model):.2f} MB\")\nfor key in results:\n    print(f\"{key}: {results[key]*100:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:40:50.114495Z","iopub.execute_input":"2025-03-14T13:40:50.114756Z","iopub.status.idle":"2025-03-14T13:44:39.669097Z","shell.execute_reply.started":"2025-03-14T13:40:50.114734Z","shell.execute_reply":"2025-03-14T13:44:39.668377Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 200/200 [03:48<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"teacher_model\nModel size: 1550.07 MB\nrouge1: 20.81\nrouge2: 3.67\nrougeL: 13.45\nrougeLsum: 13.43\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"import evaluate\nfrom datasets import load_dataset\nfrom tqdm import tqdm\n# Use the same testset to test the original student model \nstudent_model_original = AutoModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-6-6\").to(device)\n# 加载 XSum 测试集前 20 个样本\ntest_dataset = load_dataset(\"EdinburghNLP/xsum\", split=\"test[:200]\")\n\n# ROUGE 计算器\nrouge = evaluate.load(\"rouge\")\n\n# 生成摘要并收集结果\ngenerated_summaries = []\nreference_summaries = []\n\nfor sample in tqdm(test_dataset):\n    article = sample[\"document\"]\n    reference_summary = sample[\"summary\"]\n\n    # 编码输入\n    inputs = tokenizer(\n        article,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=1024,\n        padding=\"max_length\"\n    ).to(device)\n\n    # 生成摘要\n    summary_ids = student_model_original.generate(\n        **inputs,\n        max_length=400,\n        num_beams=4,\n        length_penalty=2.0,\n        no_repeat_ngram_size=3,\n        early_stopping=True\n    )\n\n    # 解码生成的摘要\n    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n    generated_summaries.append(generated_summary)\n    reference_summaries.append(reference_summary)\n\n# 计算 ROUGE 分数\nresults = rouge.compute(\n    predictions=generated_summaries,\n    references=reference_summaries,\n    use_stemmer=True\n)\n\n# 打印结果\nprint('student_model_original')\nprint(f\"Model size: {get_model_size(student_model_original):.2f} MB\")\nfor key in results:\n    print(f\"{key}: {results[key]*100:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:44:39.670031Z","iopub.execute_input":"2025-03-14T13:44:39.670360Z","iopub.status.idle":"2025-03-14T13:46:59.706043Z","shell.execute_reply.started":"2025-03-14T13:44:39.670327Z","shell.execute_reply":"2025-03-14T13:46:59.705252Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.80k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4adf4e5a21e54afab95c4c919852fcd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/460M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3747a1bfc25049c2b2e51c922d46b336"}},"metadata":{}},{"name":"stderr","text":"100%|██████████| 200/200 [02:12<00:00,  1.51it/s]\n","output_type":"stream"},{"name":"stdout","text":"student_model_original\nModel size: 877.32 MB\nrouge1: 20.28\nrouge2: 3.45\nrougeL: 13.33\nrougeLsum: 13.31\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"#\n#At last, I want to compare the directly fine tune the student model\n# 2. 加载并预处理数据集\nfrom datasets import load_dataset\n# 加载 XSUM 的 1000 个样本\nxsum_dataset = load_dataset(\"EdinburghNLP/xsum\")\ndataset  = xsum_dataset[\"train\"].shuffle(seed=42).select(range(1000))\n# 定义预处理函数，将输入文本和摘要转为token id\ndef preprocess(example):\n    # 输入为完整文章（字段名可能是 \"document\"），目标为摘要（字段名为 \"summary\"）\n    inputs = tokenizer(example[\"document\"], truncation=True, padding=\"max_length\", max_length=1024)\n    targets = tokenizer(example[\"summary\"], truncation=True, padding=\"max_length\", max_length=400)\n    # 注意：生成任务需要 labels 字段\n    labels = targets[\"input_ids\"]\n    labels = [ [t if t != tokenizer.pad_token_id else -100 for t in label] for label in labels]\n    \n    inputs[\"labels\"] = labels\n    return inputs\ntokenized_dataset = dataset.map(preprocess, batched=True, remove_columns=dataset.column_names)\ntokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:46:59.707041Z","iopub.execute_input":"2025-03-14T13:46:59.707314Z","iopub.status.idle":"2025-03-14T13:47:02.957400Z","shell.execute_reply.started":"2025-03-14T13:46:59.707290Z","shell.execute_reply":"2025-03-14T13:47:02.956649Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9247f4cdd4740d68e5778cf51c6c301"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments,DataCollatorForSeq2Seq\n# 4. 设置训练参数\n#With same training args\ntraining_args = Seq2SeqTrainingArguments(\n   \n    output_dir=\"./fintune_results\",\n    per_device_train_batch_size=4,\n    num_train_epochs=7,\n    learning_rate=5e-5,\n    warmup_ratio=0.1,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    save_strategy=\"epoch\",\n    report_to=\"none\"\n)\n\ndata_collator = DataCollatorForSeq2Seq(tokenizer, model=student_model_original)\ntrainer = Seq2SeqTrainer(\n    model=student_model_original,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\n# 开始训练\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T14:07:44.489504Z","iopub.execute_input":"2025-03-14T14:07:44.489809Z","iopub.status.idle":"2025-03-14T14:31:56.832673Z","shell.execute_reply.started":"2025-03-14T14:07:44.489765Z","shell.execute_reply":"2025-03-14T14:31:56.831797Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-10-7a3eaf41d7de>:17: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n  trainer = Seq2SeqTrainer(\n/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py:657: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n  batch[\"labels\"] = torch.tensor(batch[\"labels\"], dtype=torch.int64)\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='875' max='875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [875/875 24:09, Epoch 7/7]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>3.317400</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>2.858300</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>2.879200</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>2.537700</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.678000</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.594800</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>2.465200</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>2.624900</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>2.617800</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.605000</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>2.491300</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>2.565200</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>2.301200</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.769500</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>1.796400</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>1.866800</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.789500</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.950100</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>1.892500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.871200</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>1.712600</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>1.744100</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>1.748900</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.818700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.786800</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>1.020900</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.026400</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>1.103900</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>1.079900</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>1.100900</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>1.057900</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>1.060100</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>1.147100</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>1.054900</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.166100</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.037300</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>1.175200</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.883100</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.636600</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.591400</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.625800</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.672600</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.579800</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.576600</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.654200</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.643600</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.701400</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.622200</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.644300</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.597000</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.345600</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.339300</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.368600</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.370500</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.350800</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.405500</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.366300</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.386000</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.340500</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.380600</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.404400</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.350500</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.310900</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.247900</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.231300</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.238300</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.222700</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.260600</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.222400</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.239300</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.215300</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.234500</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.248600</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.222700</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.215500</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.170200</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.166400</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.180500</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.152300</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.172800</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.180100</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.187200</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.183100</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.179600</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.148800</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.176600</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.159200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 142, 'min_length': 56, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 2.0, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=875, training_loss=0.9988510544640677, metrics={'train_runtime': 1451.8736, 'train_samples_per_second': 4.821, 'train_steps_per_second': 0.603, 'total_flos': 7584954187776000.0, 'train_loss': 0.9988510544640677, 'epoch': 7.0})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"import evaluate\nfrom datasets import load_dataset\nfrom tqdm import tqdm\n# 加载 XSum 测试集前 20 个样本\n# From the Training loss, we can see that the fine tune is almost done, as the trainset with only 1000 samples, 7 epoche is good enough.\n# Finally, test the fine-tuned student model on the same testset.\ntest_dataset = load_dataset(\"EdinburghNLP/xsum\", split=\"test[:200]\")\n\n# ROUGE 计算器\nrouge = evaluate.load(\"rouge\")\n\n# 生成摘要并收集结果\ngenerated_summaries = []\nreference_summaries = []\n\nfor sample in tqdm(test_dataset):\n    article = sample[\"document\"]\n    reference_summary = sample[\"summary\"]\n\n    # 编码输入\n    inputs = tokenizer(\n        article,\n        return_tensors=\"pt\",\n        truncation=True,\n        max_length=1024,\n        padding=\"max_length\"\n    ).to(device)\n\n    # 生成摘要\n    summary_ids = student_model_original.generate(\n        **inputs,\n        max_length=400,\n        num_beams=4,\n        length_penalty=2.0,\n        no_repeat_ngram_size=3,\n        early_stopping=True\n    )\n\n    # 解码生成的摘要\n    generated_summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n    generated_summaries.append(generated_summary)\n    reference_summaries.append(reference_summary)\n\n# 计算 ROUGE 分数\nresults = rouge.compute(\n    predictions=generated_summaries,\n    references=reference_summaries,\n    use_stemmer=True\n)\n\n# 打印结果\n# Not bad\nprint('student_model_finetuned')\nprint(f\"Model size: {get_model_size(student_model_original):.2f} MB\")\nfor key in results:\n    print(f\"{key}: {results[key]*100:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T15:14:23.023173Z","iopub.execute_input":"2025-03-14T15:14:23.023509Z","iopub.status.idle":"2025-03-14T15:16:37.618619Z","shell.execute_reply.started":"2025-03-14T15:14:23.023480Z","shell.execute_reply":"2025-03-14T15:16:37.617891Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 200/200 [02:13<00:00,  1.50it/s]\n","output_type":"stream"},{"name":"stdout","text":"student_model_finetuned\nModel size: 877.32 MB\nrouge1: 25.49\nrouge2: 7.16\nrougeL: 17.83\nrougeLsum: 17.85\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"#We can see the results compare with distilled student model(Student model, NuppuCat/distillBart-6-6-1000xsum-8epoche), \n#teacher model without finetune on Xsum but finetuned on CNN dataset(teacher_model, facebook/bart-large-cnn), \n#the original student model(student_model_original, sshleifer/distilbart-cnn-6-6),\n#and the fine-tuned original student model (student_model_finetuned, )\n#The distilled student model reached the best performance. ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-14T13:47:02.966456Z","iopub.status.idle":"2025-03-14T13:47:02.966868Z","shell.execute_reply":"2025-03-14T13:47:02.966688Z"}},"outputs":[],"execution_count":null}]}